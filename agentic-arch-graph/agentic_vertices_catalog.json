[
  {
    "short_id": "A",
    "id": "prompt_chaining",
    "label": "Prompt Chaining",
    "aliases": [
      "Chain Composition",
      "Task Decomposition",
      "Multi-step Prompting",
      "Stepwise Orchestration"
    ],
    "layer": "reasoning_core",
    "polarity": "fluxus",
    "human_role": "none",
    "compute": "medium",
    "state": "stateless",
    "safety_surface": "medium"
  },
  {
    "short_id": "B",
    "id": "routing",
    "label": "Routing",
    "aliases": [
      "Skill Routing",
      "Policy Router",
      "Tool Router",
      "Agent Router"
    ],
    "layer": "coordination",
    "polarity": "latticus",
    "human_role": "none",
    "compute": "low",
    "state": "stateless",
    "safety_surface": "medium"
  },
  {
    "short_id": "C",
    "id": "parallelization",
    "label": "Parallelization",
    "aliases": [
      "Concurrency",
      "Batching",
      "Sharding",
      "Fan-out"
    ],
    "layer": "coordination",
    "polarity": "latticus",
    "human_role": "none",
    "compute": "high",
    "state": "stateless",
    "safety_surface": "low"
  },
  {
    "short_id": "D",
    "id": "reflection",
    "label": "Reflection",
    "aliases": [
      "Self-Reflection",
      "Self-critique",
      "Deliberate Second Pass",
      "Audit Pass"
    ],
    "layer": "reasoning_core",
    "polarity": "fluxus",
    "human_role": "optional",
    "compute": "medium",
    "state": "stateless",
    "safety_surface": "medium"
  },
  {
    "short_id": "E",
    "id": "tool_use",
    "label": "Tool Use",
    "aliases": [
      "External Tools",
      "API Calls",
      "Function Calling",
      "Plugins"
    ],
    "layer": "planning_control",
    "polarity": "latticus",
    "human_role": "none",
    "compute": "high",
    "state": "cacheable",
    "safety_surface": "high"
  },
  {
    "short_id": "F",
    "id": "planning",
    "label": "Planning",
    "aliases": [
      "Task Planning",
      "Plan-and-Act",
      "Decomposition Planning",
      "Project Planner"
    ],
    "layer": "planning_control",
    "polarity": "latticus",
    "human_role": "optional",
    "compute": "medium",
    "state": "stateful",
    "safety_surface": "medium"
  },
  {
    "short_id": "G",
    "id": "multi_agent_collaboration",
    "label": "Multi-Agent Collaboration",
    "aliases": [
      "Swarms",
      "Agent Teams",
      "Agent Mesh",
      "Orchestrated Agents"
    ],
    "layer": "coordination",
    "polarity": "latticus",
    "human_role": "optional",
    "compute": "high",
    "state": "stateful",
    "safety_surface": "medium"
  },
  {
    "short_id": "H",
    "id": "memory_management",
    "label": "Memory Management",
    "aliases": [
      "Long-Term Memory",
      "Working Memory",
      "Context Cache",
      "Vector Store"
    ],
    "layer": "memory_learning",
    "polarity": "fluxus",
    "human_role": "none",
    "compute": "medium",
    "state": "stateful",
    "safety_surface": "medium"
  },
  {
    "short_id": "I",
    "id": "learning_adaptation",
    "label": "Learning and Adaptation",
    "aliases": [
      "Continuous Improvement",
      "Policy Update",
      "Parameter Update",
      "Self-Tuning"
    ],
    "layer": "memory_learning",
    "polarity": "fluxus",
    "human_role": "optional",
    "compute": "medium",
    "state": "stateful",
    "safety_surface": "high"
  },
  {
    "short_id": "J",
    "id": "goal_setting_monitoring",
    "label": "Goal Setting and Monitoring",
    "aliases": [
      "OKRs",
      "Objectives",
      "Target Tracking",
      "Milestone Tracking"
    ],
    "layer": "planning_control",
    "polarity": "latticus",
    "human_role": "optional",
    "compute": "low",
    "state": "stateful",
    "safety_surface": "medium"
  },
  {
    "short_id": "K",
    "id": "exception_handling_recovery",
    "label": "Exception Handling and Recovery",
    "aliases": [
      "Fallbacks",
      "Retries",
      "Circuit Breaker",
      "Timeout Recovery"
    ],
    "layer": "oversight_safety",
    "polarity": "latticus",
    "human_role": "optional",
    "compute": "low",
    "state": "cacheable",
    "safety_surface": "high"
  },
  {
    "short_id": "L",
    "id": "human_in_the_loop",
    "label": "Human-in-the-Loop",
    "aliases": [
      "HITL",
      "Reviewer",
      "Approval Gate",
      "Escalation"
    ],
    "layer": "oversight_safety",
    "polarity": "latticus",
    "human_role": "required",
    "compute": "low",
    "state": "stateless",
    "safety_surface": "high"
  },
  {
    "short_id": "M",
    "id": "retrieval_rag",
    "label": "Retrieval - RAG",
    "aliases": [
      "Retrieval Augmented Generation",
      "Knowledge Retrieval",
      "Context Injection",
      "Document Grounding"
    ],
    "layer": "memory_learning",
    "polarity": "latticus",
    "human_role": "none",
    "compute": "high",
    "state": "cacheable",
    "safety_surface": "medium"
  },
  {
    "short_id": "N",
    "id": "inter_agent_communication",
    "label": "Inter-Agent Communication",
    "aliases": [
      "Agent Messaging",
      "Protocol Bus",
      "Blackboard",
      "Pub/Sub"
    ],
    "layer": "coordination",
    "polarity": "latticus",
    "human_role": "optional",
    "compute": "low",
    "state": "stateful",
    "safety_surface": "medium"
  },
  {
    "short_id": "O",
    "id": "resource_aware_optimization",
    "label": "Resource-Aware Optimization",
    "aliases": [
      "Budgeting",
      "Latency-Cost Tradeoff",
      "Compute Allocation",
      "Knob Tuning"
    ],
    "layer": "planning_control",
    "polarity": "latticus",
    "human_role": "none",
    "compute": "high",
    "state": "cacheable",
    "safety_surface": "medium"
  },
  {
    "short_id": "P",
    "id": "prioritization",
    "label": "Prioritization",
    "aliases": [
      "Ranking",
      "Queue Ordering",
      "Scheduling",
      "Greedy Selection"
    ],
    "layer": "planning_control",
    "polarity": "latticus",
    "human_role": "optional",
    "compute": "low",
    "state": "stateless",
    "safety_surface": "medium"
  },
  {
    "short_id": "Q",
    "id": "evaluation_monitoring",
    "label": "Evaluation and Monitoring",
    "aliases": [
      "Evals",
      "Telemetry",
      "Metrics",
      "A/B Tests"
    ],
    "layer": "oversight_safety",
    "polarity": "latticus",
    "human_role": "optional",
    "compute": "medium",
    "state": "stateful",
    "safety_surface": "high"
  },
  {
    "short_id": "R",
    "id": "guardrails_safety",
    "label": "Guardrails and Safety",
    "aliases": [
      "Policy Enforcement",
      "Content Filters",
      "Safety Checks",
      "Red Teaming"
    ],
    "layer": "oversight_safety",
    "polarity": "latticus",
    "human_role": "optional",
    "compute": "low",
    "state": "stateless",
    "safety_surface": "high"
  },
  {
    "short_id": "S",
    "id": "reasoning_techniques",
    "label": "Reasoning Techniques",
    "aliases": [
      "Tree-of-Thought",
      "Graph-of-Thought",
      "Scratchpad",
      "Debate"
    ],
    "layer": "reasoning_core",
    "polarity": "fluxus",
    "human_role": "none",
    "compute": "medium",
    "state": "stateless",
    "safety_surface": "low"
  },
  {
    "short_id": "T",
    "id": "exploration_discovery",
    "label": "Exploration and Discovery",
    "aliases": [
      "Hypothesis Generation",
      "Search",
      "Divergent Thinking",
      "Probing"
    ],
    "layer": "reasoning_core",
    "polarity": "fluxus",
    "human_role": "optional",
    "compute": "medium",
    "state": "stateless",
    "safety_surface": "low"
  }
]